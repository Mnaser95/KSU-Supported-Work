{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c92ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.fft import fft, fftfreq, ifft\n",
    "import scipy.fftpack\n",
    "from matplotlib import *\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import *\n",
    "from scipy import signal\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import mne\n",
    "from mne.time_frequency import psd_welch\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from sklearn.metrics import r2_score\n",
    "from mne.decoding import CSP \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import svm\n",
    "import pywt\n",
    "from sklearn.model_selection import KFold\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d440da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2552. 2530. 2697. 2522. 2475. 2055. 2235. 2070. 2062. 2302. 2395. 2375.\n",
      " 2447. 2967. 2545.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnaser1\\AppData\\Local\\Temp\\ipykernel_31956\\2270942163.py:2: DeprecationWarning: scipy.floor is deprecated and will be removed in SciPy 2.0.0, use numpy.floor instead\n",
      "  m2_sample_number_beg_movement=floor(m2_time_stamps_beg_movement*250)\n"
     ]
    }
   ],
   "source": [
    "m2_time_stamps_beg_movement=np.array([10.21,10.12,10.79,10.09,9.9,8.22,8.94,8.28,8.25,9.21,9.58,9.5,9.79,11.87,10.18])\n",
    "m2_sample_number_beg_movement=floor(m2_time_stamps_beg_movement*250)\n",
    "print(m2_sample_number_beg_movement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14995605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "rest shape (750, 8)\n",
      "size of rest file accross all sessions is: (11250, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "walk shape (750, 8)\n",
      "size of walk file accross all sessions is: (11250, 8)\n",
      "size of walk and rest accross all sessions is: (22500, 8)\n"
     ]
    }
   ],
   "source": [
    "# first four rows of OpenBCI were removed manually\n",
    "rest_concat=np.ndarray(shape=(1,8))\n",
    "directory = os.fsencode(r\"C:\\Users\\mnaser1\\OneDrive - Kennesaw State University\\Desktop\\PhD-S3\\Research\\Gait intention\\M2\\r\")\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename_l = list(os.fsdecode(file))\n",
    "    current_file= str(r\"C:\\Users\\mnaser1\\OneDrive - Kennesaw State University\\Desktop\\PhD-S3\\Research\\Gait intention\\M2\\r\")+str(r\"\\\\\")+str(os.fsdecode(file))\n",
    "    rest=pd.read_csv(current_file, sep=\",\")\n",
    "    rest=rest[[\" EXG Channel 0\",\" EXG Channel 1\",\" EXG Channel 2\",\" EXG Channel 3\",\" EXG Channel 4\",\" EXG Channel 5\",\" EXG Channel 6\",\" EXG Channel 7\"]]\n",
    "    rest=rest.tail(750)  # keep last 3s of recording for rest\n",
    "    print(\"rest shape\",rest.shape)\n",
    "    rest_np=np.array(rest)\n",
    "    rest_concat=np.concatenate((rest_concat,rest_np),axis=0)\n",
    "rest_concat=np.delete(rest_concat,0,axis=0)\n",
    "print(\"size of rest file accross all sessions is:\",rest_concat.shape)\n",
    "\n",
    "\n",
    "i=0\n",
    "walk_concat=np.ndarray(shape=(1,8))\n",
    "directory = os.fsencode(r\"C:\\Users\\mnaser1\\OneDrive - Kennesaw State University\\Desktop\\PhD-S3\\Research\\Gait intention\\M2\\w\")\n",
    "for file in os.listdir(directory):\n",
    "    filename_l = list(os.fsdecode(file))\n",
    "    current_file= str(r\"C:\\Users\\mnaser1\\OneDrive - Kennesaw State University\\Desktop\\PhD-S3\\Research\\Gait intention\\M2\\w\")+str(r\"\\\\\")+str(os.fsdecode(file))\n",
    "    walk=pd.read_csv(current_file, sep=\",\")\n",
    "    walk=walk[[\" EXG Channel 0\",\" EXG Channel 1\",\" EXG Channel 2\",\" EXG Channel 3\",\" EXG Channel 4\",\" EXG Channel 5\",\" EXG Channel 6\",\" EXG Channel 7\"]]\n",
    "    walk_np=np.array(walk)\n",
    "    beg_here=int(m2_sample_number_beg_movement[i])\n",
    "    walk_np=walk_np[:beg_here]\n",
    "    beg_here2=len(walk_np)-750\n",
    "    walk_np=walk_np[beg_here2:beg_here2+750]\n",
    "    print(\"walk shape\",walk_np.shape)\n",
    "    walk_concat=np.concatenate((walk_concat,walk_np),axis=0)\n",
    "    i=i+1\n",
    "walk_concat=np.delete(walk_concat,0,axis=0)\n",
    "print(\"size of walk file accross all sessions is:\",walk_concat.shape)\n",
    "\n",
    "full_data=np.concatenate((rest_concat,walk_concat),axis=0)\n",
    "print(\"size of walk and rest accross all sessions is:\",full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a39ced5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events=np.ndarray(shape=(1,3),dtype=int)\n",
    "for i in range(0,len(full_data),750):\n",
    "    my_index=i\n",
    "    if my_index<len(walk_concat):\n",
    "        my_label=1\n",
    "    else:\n",
    "        my_label=2\n",
    "    current_event=np.array([my_index, 0 ,my_label])   \n",
    "    current_event=np.reshape(current_event,(1,3))\n",
    "    events=np.append(events,current_event,axis=0)\n",
    "events=np.delete(events,0,axis=0)\n",
    "#print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b25726d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=8, n_times=22500\n",
      "    Range : 1 ... 22500 =      0.004 ...    90.000 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 13 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 13.00 Hz\n",
      "- Upper transition bandwidth: 3.25 Hz (-6 dB cutoff frequency: 14.62 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnaser1\\AppData\\Local\\Temp\\ipykernel_31956\\3010243025.py:2: DeprecationWarning: scipy.transpose is deprecated and will be removed in SciPy 2.0.0, use numpy.transpose instead\n",
      "  full_data_transposed=transpose(full_data)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>8 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>7.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>13.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:01:30 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawArray | 8 x 22500 (90.0 s), ~1.4 MB, data loaded>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels=[\"FP1\",\"FP2\",\"C3\",\"C4\",\"F7\",\"F8\",\"F3\",\"F4\"]\n",
    "full_data_transposed=transpose(full_data)\n",
    "info=mne.create_info(ch_names=channels, sfreq=250, ch_types='eeg')\n",
    "raw =mne.io.RawArray(full_data_transposed, info,1)\n",
    "raw.set_eeg_reference('average')\n",
    "raw.filter(7, 13, fir_design='firwin', skip_by_annotation='edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "117d7cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 750 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "event_id = dict(rest=1, walk=2)\n",
    "tmin, tmax = .004,3\n",
    "#reject=dict(eeg=10000)\n",
    "epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=channels, baseline=None, preload=True,reject=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa38720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avergae score over cvs for 625 - 750 is: 0.7916666666666667\n",
      "avergae score over cvs for 500 - 750 is: 0.7916666666666667\n",
      "avergae score over cvs for 375 - 750 is: 0.75\n",
      "avergae score over cvs for 250 - 750 is: 0.875\n",
      "avergae score over cvs for 125 - 750 is: 0.875\n",
      "avergae score over cvs for 0 - 750 is: 0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "##### LDA-raw\n",
    "moving_window_acc_arr=[]\n",
    "epochs_data = epochs.get_data()\n",
    "avg_microv=np.ndarray(shape=(30,750),dtype=float)\n",
    "sec_inc=.5\n",
    "sec_inc_samp=sec_inc*250\n",
    "num_intervals=int(3/sec_inc)\n",
    "\n",
    "for counter in range(1,num_intervals+1):\n",
    "    s_end=750\n",
    "    s_start=int(s_end-(sec_inc_samp*counter))\n",
    "    for ii in range(0,30):\n",
    "        for i in range (s_start,s_end):\n",
    "            avg_microv[ii][i]=(epochs_data[ii][0][i]+epochs_data[ii][1][i]+epochs_data[ii][2][i]+epochs_data[ii][3][i]+epochs_data[ii][4][i]+epochs_data[ii][5][i]+epochs_data[ii][6][i]+epochs_data[ii][7][i])/8\n",
    "            #avg_microv[ii][i]=(epochs_data[ii][2][i]+epochs_data[ii][3][i])/2\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    my_labels=epochs.events[:, -1]\n",
    "    scores = []\n",
    "\n",
    "    cv = ShuffleSplit(4, test_size=0.20, random_state=20)\n",
    "    clf =lda\n",
    "    scores = cross_val_score(clf, avg_microv, my_labels, cv=cv, n_jobs=None)\n",
    "    #print(scores)\n",
    "    print(\"avergae score over cvs for\",s_start,\"-\",s_end,\"is:\",np.mean(scores))\n",
    "    mean_score=np.mean(scores)\n",
    "    #print(scores)\n",
    "    moving_window_acc_arr.append(mean_score)\n",
    "#plt.plot(moving_window_acc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be74c23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avergae score over cvs for 625 - 750 is: 0.95\n",
      "avergae score over cvs for 500 - 750 is: 0.95\n",
      "avergae score over cvs for 375 - 750 is: 0.95\n",
      "avergae score over cvs for 250 - 750 is: 0.95\n",
      "avergae score over cvs for 125 - 750 is: 0.95\n",
      "avergae score over cvs for 0 - 750 is: 0.2\n"
     ]
    }
   ],
   "source": [
    "##### svm-raw\n",
    "moving_window_acc_arr=[]\n",
    "epochs_data = epochs.get_data()\n",
    "avg_microv=np.ndarray(shape=(30,750),dtype=float)\n",
    "sec_inc=.5\n",
    "sec_inc_samp=sec_inc*250\n",
    "num_intervals=int(3/sec_inc)\n",
    "\n",
    "for counter in range(1,num_intervals+1):\n",
    "    s_end=750\n",
    "    s_start=int(s_end-(sec_inc_samp*counter))\n",
    "    for ii in range(0,30):\n",
    "        for i in range (s_start,s_end):\n",
    "            avg_microv[ii][i]=(epochs_data[ii][0][i]+epochs_data[ii][1][i]+epochs_data[ii][2][i]+epochs_data[ii][3][i]+epochs_data[ii][4][i]+epochs_data[ii][5][i]+epochs_data[ii][6][i]+epochs_data[ii][7][i])/8\n",
    "            #avg_microv[ii][i]=(epochs_data[ii][2][i]+epochs_data[ii][3][i])/2\n",
    "\n",
    "    my_labels=epochs.events[:, -1]\n",
    "    scores = []\n",
    "\n",
    "    cv = ShuffleSplit(4, test_size=0.15, random_state=20)\n",
    "    clf =svm.SVC(kernel='linear',C=100, gamma=.1)    \n",
    "    scores = cross_val_score(clf, avg_microv, my_labels, cv=cv, n_jobs=None)\n",
    "    #print(scores)\n",
    "    print(\"avergae score over cvs for\",s_start,\"-\",s_end,\"is:\",np.mean(scores))\n",
    "    mean_score=np.mean(scores)\n",
    "    #print(scores)\n",
    "    moving_window_acc_arr.append(mean_score)\n",
    "#plt.plot(moving_window_acc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11600905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058289b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
